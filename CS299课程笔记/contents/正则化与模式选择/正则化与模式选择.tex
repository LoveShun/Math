\section{正则化与模式选择}
\subsection{模式选择}
在以下的内容中，我们定义$\mathcal{M} = \{M_1, M_2, \dots, M_d\}$为我们的Models Sets。

\subsubsection{交叉验证}
\begin{enumerate}
	\item Hold-Out Cross Validation(Simple Cross Validation)
	\begin{enumerate}
		\item 将数据集分为$70\%$的测试集与$30\%$的交叉验证集两份数据
		\item 使用$70\%$的测试集在Model Sets中对每个Model进行训练
		\item 用剩下的$30\%$对每个训练结果进行验证，选出经验误差$\hat{\varepsilon}_{S_{cv}}(h)$最小的作为我们要的Model，然后用所有的数据对选择的Model在进行训练
		\item $70\%$与$30\%$的比例可自行调整
		\item 使用此方法留给交叉验证集的数据太多了，于是后了下面的方式
	\end{enumerate}

	\item $k$-Fold Cross Validation
	\begin{enumerate}
		\item 将数据分成$k$份($k$的大小小于数据集大小$m$即可)
		\item 将第1份数据当做交叉训练集，用其余$k-1$份进行训练，并计算此时每个Model($M_i$)的误差$\hat{\varepsilon}_{S_1}(h_{i1})$
		\item 将第2份数据当做交叉训练集，用其余$k-1$份进行训练，并计算此时每个Model($M_i$)的误差$\hat{\varepsilon}_{S_2}(h_{i2})$
		\item 将第j份数据当做交叉训练集，用其余$k-1$份进行训练，并计算此时每个Model($M_i$)的误差$\hat{\varepsilon}_{S_j}(h_{ij})$
		\item 将第k份数据当做交叉训练集，用其余$k-1$份进行训练，并计算此时每个Model($M_i$)的误差$\hat{\varepsilon}_{S_k}(h_{ik})$
		\item 对每个Model用不同交叉验证集的到的误差取均值，选出误差最小的作为我们要的Model
		\item 使用$k$-Fold Cross Validation的缺点是计算量大，如$k=10$，我们就需要训练$10$次
		\item 特别地，若我们取$k=m$，则每次只留一个数据当做交叉验证集，我们将这种方式成为留一交叉验证(Leave-One-Out Cross Validation)，一般只有在数据量很少时才会用此方法

	\end{enumerate}
\end{enumerate}


\subsection{特征选择}
当我们要训练的维度$n$非常大($n >> m$)，但是并不一定所有的维度都对训练有利时，我们就希望能够选取部分的特征进行训练。

\subsubsection{向前搜索}
\begin{enumerate}
	\item 待添加
\end{enumerate}










