
\subsection{软间隔SVM}
\begin{enumerate}
	\item 为了让算法在非线性可分的数据集中也能够正常工作，同时，也为了减小离群点对决策边界影响，我们对算法进行一下优化
	\begin{align}
		&\text{优化目标：} \\
		& \qquad \min_{\gamma, w, b} \frac{1}{2}\|w\|^2 + C\sum_{i=1}^{m}\xi_i \\
		&\text{约束条件：} \\
		& \qquad y^{(i)}(w^Tx^{(i)} + b) \geq 1-\xi_i, \quad i=1, 2, \dots, m \\
		& \qquad \xi_i \geq 0, i=1,\dots,m
	\end{align}
	\item 此时，就允许有部分的点其函数间隔小于$1$，如果有某个点的函数间隔小于$1$，我们就可以通过$C\xi_i$对目标函数进行惩罚。参数$C$可以控制让$\|w\|^2$尽可能大，与让大部分的点的函数间隔大于$1$之间的权重。
	\item 更新后的拉格朗日函数：
	\begin{align}
		\mathcal{L}(w,b,\xi,\alpha,r) = \frac{1}{2}w^Tw + C\sum_{i=1}^{m}\xi_i -C\sum_{i=1}^{m}\alpha_i\left[y^{(i)}(x^Tw + b)-1+\xi_i\right]-\sum_{i=1}^{m}r_i\xi_i
	\end{align}
	\item 其对偶问题
	\begin{align}
		&\text{优化目标：} \\
		& \qquad \max_{\alpha}W(\alpha)=\sum_{i=1}^{m} \alpha_i -\frac{1}{2}\sum_{i,j=1}^{m}y^{(i)}y^{(j)}\alpha_i\alpha_j\langle x^{(i)},x^{(j)} \rangle \\
		&\text{约束条件：} \\
		& \qquad 0 \leq \alpha_i \leq C, \quad i=1, 2, \dots, m \\
		& \qquad \sum_{i=1}^{m}\alpha_i y^{(i)} = 0
	\end{align}
	\item KKT对偶补充条件为：
	\begin{align}
		\alpha_i = 0 &\Rightarrow y^{(i)}(w^Tx^{(i)}+b) \geq 1\\
		\alpha_i = C &\Rightarrow y^{(i)}(w^Tx^{(i)}+b) \leq 1\\
		0 < \alpha < C &\Rightarrow y^{(i)}(w^Tx^{(i)}+b) = 1\\
	\end{align}

\end{enumerate}















